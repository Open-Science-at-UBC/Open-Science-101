
﻿
OS 101 Unit 5: Challenges and Constraints

## Unit 5 Objectives

### Introductions
**If Open Science is so great, why isn't it more wide spread?** <mark>If Open Science brings so many benefits to researchers, science, and society, you may wonder why OS practices aren't more widespread. Technology has radically changed the nature of scientific research by making it possible to</mark>

- <mark>create, store, process, and share huge quantities of data;
- <mark>make computer simulations of elaborate scenarios in addition to experimentation; and **I dont' know if I understand the second part of this sentence *experimentation*.**
- <mark>collaborate with coworkers and citizen scientists anywhere in the world.

*I feel like all the highlghted, while interesting, is not relevant to the question introduced, **why isn't OS more widespread?**.*

We have <del>both</del> the technological and <del>the</del> <mark>imperative - *perhaps articulate the type of imperative? ie moral, social etc.*</mark> to open science in order to better address problems facing our society and our world.<del>, so what's keeping us from realizing our ideal Open Science research culture?</del> This unit looks at the difficulties in implementing Open Science and strategies that will help overcome them.

### Objectives

On completion of Unit 5, *you should be able to <mark>articulate (I feel like list is perhaps too simple a task)</mark> and identify a strategy for addressing each of the following hindrances to practicing Open Science.* <del>list and describe the following five categories of limits and challenges to Open Science and give an example of a strategy for dealing with each:</del>

- lack of **incentives** <del>for adopting OS practices</de>
- **publishing** <del>industry</del> practices
- lack of **knowledge**
- **privacy** and **intellectual property** rights

*I would suggest either only bolding key terms or dropping the bold all together from the bulleted list*



## Incentives and Rewards

### The Current Reward System
<del>One of the biggest obstacles in the path to Open Science comes from the difficulty of achieving a change in the way scientists are rewarded for their work, from publication in high-status journals to progression in their careers. What are the criteria used to compensate and promote science?</del> As we saw in Unit 2, flashy science may trump good science. <mark>The actors involved here are four: researchers, publishers, employers, and funders. Traditional researcher outputs, *the academic paper*, are coordinated by publishers, while researcher rewards, *tenure, wages, and grants*, are handled by their employers and/or funders.</mark>

<mark>As you'll recall,</mark> journals want to publish exciting research. <mark> You could say this is good business sense.</mark>

<mark>Funders also want to fund research with clear, novel, and measurable outputs. They obviously want to have something to show for their investment and they have to justify *why* they funded a given project.</mark>

<mark>Employers want to know that their institution is having impact -- institutional impact is a measure of researcher impact.</mark>

<mark>Researcher impact</mark> <del>And the career progress of scientists</del> is <mark>largely</mark> gauged by the number of times their research is quoted by others, the prestige of the journals they publish in, and how much funding they can get. <mark>That is, metrics largely associated with the outputs of journals.</mark><del>Most of the organizations that employ scientists, such as universities, large research institutes, and governments, are huge beasts with complicated organizational structures, traditions, rules, and procedures; change comes to them at a glacial pace.</del> *I like this, but I think it should go elsewhere - it's not earmarking the current reward system, it's highlighting why it's hard to change.*

<mark>You can see we have a bit of tangled web here. Researchers may want to change their practices, but if this is going to adversely impact how they're published, it's going to have cascading effects that are not in their favour with their employers and funders. At the same time, funders and employers struggle with how else to *measure* research impact to coordinate funding and to demonstrate value.</mark>

### Strategies for Change

<mark>Strategies for change very much centre on how *value* and *impact* are interpreted and understood in the context of research. And many large organizations representing researcehrs, publishers, employers, and funders, have started to re-evaluate what is valuable and what impacts warrant merit.</mark>

<mark>There have been a few key moments that have sparked and motivated soem of these shifts.</mark>

#### Metrics for assessment

<mark>In 2012, at the Annual Meeting of the American Society for Cell Biology in San Francisco, the Declaration on Research Assessment (DORA) was produced. DORA is a call on all parties invovled in the research process to critically re-evaluate how research is assessed for merit. It has since turned into a worldwide initiative with thousands of individual and organizational supporters. [You can read more about DORA here.](https://sfdora.org/)</mark>

#### Funder requirements

<mark>Since 2015 *it goes back earlier, but I think this is when it became official for all three* the three major Canadian funders</mark> <del>Nevertheless, awareness of the advantages of Open Science practices is growing rapidly, many of these large organizations have started to introduce changes. For example, the three major Canadian research agencies</del> -- the National Sciences and Engineering Research Council (NSERC), the Social Sciences and Humanities Research Council (SSHRC), and the Canadian Institutes of Health Research (CIHR) -- <del>now require</del> <mark>have required that</mark> recipients of their research grants to provide open access <del>to</del> the resulting papers within a year of publication. <mark>These same agencies are currently working on a similar policy for research data. These efforts have been mirrored by other federal and private granting agencies across the world. [You can read more about the Tri-Agencies Open Access Policy here.](https://www.science.gc.ca/eic/site/063.nsf/eng/h_F6765465.html)</mark>  

#### Journal efforts

<mark>In 2014, the journal *Psychological Science* broke new ground by giving authors the opportunity to signal how open their practices were. The journal would post a badge to papers showing readers if the the data and materials used to support the publication were open. Before badges were introduced less than 3% of papers in *Psychological Science* reported that their data was open. By mid 2015, this number had risen to 39%.</mark> * Kidwell, M. C., Lazarević, L. B., Baranski, E., Hardwicke, T. E., Piechowski, S., Falkenberg, L.-S., … Nosek, B. A. (2016). Badges to Acknowledge Open Practices: A Simple, Low-Cost, Effective Method for Increasing Transparency. PLOS Biology, 14(5), e1002456. https://doi.org/10.1371/journal.pbio.1002456


<del>Another area of change is a move toward basing the hiring, tenure, and promotion of scientists on factors overlooked by the current evaluation system, including</del>
- <del>the quality (integrity) of the science
- <del>the level of openness and transparency provided by authors at all stages of the research cycle
- <del>the level of engagement with the stakeholders in designing and conducting studies
- <del>the potential impact of the research on society.

<del>Progress in the area of revising assessment of scientists will likely prove slow, but scientists and leaders in the academic world are beginning to talk about reforming the process for assessing scientists. For example, a workshop in Washington, DC, in 2017 produced an a document identifying six key principles to guide reforms to incentives and rewards, as well as next steps to take to transform research and policy.

<del>### Example: Undergraduate Open Science Research Awards
- <del>idea of undergraduate research awards contingent on OS practices? could propose a fictitious scenario</del>

<mark>### Activity

<mark>Take a few minutes and further explore one of the examples above.</mark>

## Publishing Industry Practices

**_NB: May change this section to cover a range of publishing reforms, and have a dialogue-based example of graduate student publishing in a registered report; this is probably something students will relate to better, and would also change the order of this section from general to specific. Could cover the reforms Eric introduced at Psychological Science in the first part._**

Publishers of journals can <mark>do a lot to support more robust science and to encourage a culture of open amongst researchers. As we saw, *Psychological Science* provided a way for researchers to communicate how open they were in a simple, effective way. </mark>

<mark>As yo might recall from unit #?, one of the issues researchers face for getting published, is the need for their results to be positive. To combat this, and to encourage really good science, a handful of journals have started to support a new publishing model called Registered Reports.</mark>

<mark>In a traditional paper, peer review happens when a paper is submitted to the journal for publication. That is, *after* the research has been done. This process encourages researchers to revisit their findings and try to find positive results where they couldn't before. This phenomenon is commonly known as p-hacking. We'll look at exactly what p-hacking is in later modules.</mark>

<mark>In Registered Reports, researchers submit their planned research project to a journal and *the plan is reviewed*. If the plan is accepted, the journal guarantees that they will publish the article, whether the findings are positive or not! Peer review of the manuscript still occurs. But now the researcher is less concerned with finding positive results then they are about doing the best possible research, because their publication is guaranteed.</mark>

<mark>[You can read more about Registered Reports and see what the process looks like here.](https://cos.io/rr/)</mark>

*I'm undecided about the diagram.*

### Activity
<mark>Brainstorm 3 other ways in which journals could encourage better and more open research.</mark>

<del>make many improvements to their practices to ensure that they're publishing quality science and not merely flashy science and that their readers can access all important outputs of the research process transparently. Many journals -- over 200 in different subject areas -- have adopted a new pre-publication process called Registered Reports. Registered Reports introduces peer review of studies at the design stage so that potential problems with the study design can be improved and researchers are less likely to introduce Questionable Research Practices into their papers.

<del>These diagrams show how the Registered Reports format differs from the traditional publishing process format:
*(Are diagrams helpful here? If so, I'll make these myself in a different format. Couldn't find one for the traditional publication process.)*

<del>#### Traditional Publication
<del>#### Registered Reports
![Registered Reports Process](https://cdn.cos.io/media/images/registered_reports.width-800.png)
<del>Under Registered reports, when a study design passes the Stage 1 review by scientific peers, its publication in the journal is guaranteed -- <del>whether or not it produces flashy findings!

### Example: Reforms at Psychological Science (Eric)

## Lack of Knowledge
Most researchers <del>today haven't been trained in Open Science practices. They may</del><mark>would likely</mark> agree philosophically with opening science, but may not know where to start in terms of modifying their practices. <mark>And</mark> those in later stages of their career may think that change is too difficult, even if their graduate students try to engage them in talking about Open Science.

### A Learning Curve
Learning a new way of conducting science involves time <mark>and effort</mark>.<del>, and you know that old equation "time = money"!</del>

<mark>Depending on where you are in your career, this time and effort is more or less valuable and easier or harder to come by. For example, </mark>people at later stages of their careers may <mark>struggle with</mark> <del>prove more reluctant to learn about open science, and resent</del> the time that learning will take away from their current responsibilities <mark>that have grown over the years, including managing students, applying for grants, teaching etc</mark>.

<mark>The fact is, Open Science practices involve investing more time at the start of a research project, because they require you to think through the entire project, map out what you're going to do, and to try and account for potential areas of error before they happen.</mark> However, such an investment pays off in increased scientific rigour and less time spent on the end of the project.

Embracing Open Science <del>education</del> may also mean having to grasp new technologies, and some people, even in the sciences, feel discomfort with learning new tech.

Finally, researchers may be concerned with <mark>all</mark> the costs <mark>potentially associated with Open Science, whether that be</mark> <del>of</del> keeping data in an open repository <mark>or fear of the old adage time = money!</mark><del>. Low-cost or free options may be available either through a university or through OSF, which provides **free** storage for an unlimited quantity of data.</del>

### Advocating for Open
To <mark>help alleviate aspects of this learning curve</mark><del> close this gap in education</del>, Open Science advocates seek to make information about Open Science benefits, tools, and practices available to researchers at all levels. Initiatives include

- free<mark>, easy to use</mark> tools<mark>that don't require coding</mark> like the Open Science Framework, a project management and networking site that allows researchers to display and interact with all products of their research
- <mark>free storage for researchers, whether through third parties like [OSF](https://osf.io) or [Zenodo](https://zenodo.org/), or through one's institution. At UBC, we have [cIRcle](https://circle.ubc.ca/) for publications, and [Dataverse](https://dataverse.scholarsportal.info/dataverse/ubc) for data.</mark>
- OS education programs (including this one) at universities aimed at undergraduates, graduates, and early career researchers
- mentoring programs that team a researcher new to OS with one experienced with OS methods <mark>*Do you have an example?*</mark>
- courses in specific aspects of Open Science, such as those offered by the [FOSTER portal (a project of the European Union)](https://www.fosteropenscience.eu/courses)

This Canvas module serves as the first step of an OS undergraduate university education program: it's funded by a grant from the UBC Excellence fund aimed partially at making Open Science practices second nature to undergraduate student. This kind of education at the start of university, we hope, will "filter up" as future scientists graduate with a familiarity with OS! <mark>I can't decide if this is needed!</mark>

### Example <mark>I don't know if we need an example here</mark>
- example: undergraduate OS program, workshops/seminars, COS ambassadors program, tutorials/guides, books, etc.
- lack of knowledge about research study design, QRPs --> opportunity to inform

## Privacy and Intellectual Property Rights
**_Take a look at this short video about The Neuro here. https://montreal.ctvnews.ca/montreal-s-neuro-and-ai-community-at-heart-of-world-open-science-movement-1.3568039. The video is about 5 minutes -- could possibly just embed the whole thing or could upload a much shorter clip covering specific comments about IP. Not sure how long the link would be valid. The article itself is also interesting, especially the controversy about scientists continuing to publish "in expensive -- and exclusive -- commercial journals, a practice that reflects part of the academic culture that is slow to change."_**

- fear of being scooped - free market incentive to create in conflict with opening science - public/private partnership issues - more important in some areas of study than in others - e.g. pharmaceutical industry
- a balance is needed between creating incentives for individuals or groups to exploit new scientific knowledge for financial gain and societal benefits through the products and services that are developed and the macroeconomic benefits that accrue when knowledge is broadly available and can be exploited creatively in a wide variety of ways.
- confidentiality of data (e.g. patient names, demographic information) - solution: anonymization of data - ensure security requirements for privacy of data are met (not all obstacles can be overcome)-
